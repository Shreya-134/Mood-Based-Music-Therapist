{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless fer\n",
    "\n",
    "import cv2\n",
    "from fer import FER\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import collections\n",
    "\n",
    "# Initialize FER emotion detector\n",
    "emotion_detector = FER()\n",
    "\n",
    "# Prompt for a unique user ID or name\n",
    "user_id = input(\"Enter your user ID or name: \").strip()\n",
    "filename = f\"{user_id}_emotion_log.csv\"  # Create a unique filename for each user\n",
    "\n",
    "# Start video capture (from webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Open a unique CSV file to save the log for the specific user\n",
    "with open(filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Timestamp', 'Emotion'])  # Header row\n",
    "\n",
    "    while True:\n",
    "        # Track emotions for each 1-minute interval\n",
    "        start_time = datetime.now()\n",
    "        end_time = start_time + timedelta(minutes=1)\n",
    "        minute_emotions = []\n",
    "\n",
    "        # Collect emotions within the 1-minute interval\n",
    "        while datetime.now() < end_time:\n",
    "            # Capture frame-by-frame from the webcam\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Detect emotions in the frame\n",
    "            emotions = emotion_detector.detect_emotions(frame)\n",
    "\n",
    "            # Collect detected emotions for this 1-minute period\n",
    "            for emotion_data in emotions:\n",
    "                emotion = emotion_data['emotions']\n",
    "                dominant_emotion = max(emotion, key=emotion.get)  # Find the dominant emotion\n",
    "                minute_emotions.append(dominant_emotion)\n",
    "\n",
    "            # Draw bounding boxes and captions on the frame in real-time\n",
    "            for emotion_data in emotions:\n",
    "                bbox = emotion_data['box']\n",
    "                dominant_emotion = max(emotion_data['emotions'], key=emotion_data['emotions'].get)\n",
    "                caption = f\"Emotion: {dominant_emotion}\"\n",
    "                \n",
    "                # Draw bounding box and emotion text\n",
    "                cv2.rectangle(frame, (bbox[0], bbox[1]), \n",
    "                              (bbox[0] + bbox[2], bbox[1] + bbox[3]), \n",
    "                              (0, 255, 0), 2)\n",
    "                cv2.putText(frame, caption, \n",
    "                            (bbox[0], bbox[1] - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.9, (36, 255, 12), 2)\n",
    "\n",
    "            # Display the resulting frame with emotion captions\n",
    "            cv2.imshow('Emotion Detection', frame)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                exit()\n",
    "\n",
    "        # After 1 minute, determine the dominant emotion for the period\n",
    "        if minute_emotions:\n",
    "            overall_dominant_emotion = collections.Counter(minute_emotions).most_common(1)[0][0]\n",
    "            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "            print(f\"Detected Emotion for Last 1 Minute: {overall_dominant_emotion}\")\n",
    "            \n",
    "            # Ask for user confirmation\n",
    "            user_response = input(f\"Is '{overall_dominant_emotion}' the correct detected emotion? (yes/no): \").strip().lower()\n",
    "\n",
    "            if user_response == 'yes':\n",
    "                print(f\"Final confirmed emotion: {overall_dominant_emotion}\")\n",
    "                writer.writerow([timestamp, overall_dominant_emotion])  # Log the confirmed emotion\n",
    "            else:\n",
    "                print(\"Retrying detection for another minute...\")\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13481ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
